# Lab 3 ‚Äî Tests First

## Goal

Turn acceptance criteria into tests, then code. This enforces the "proof culture" where tests drive implementation.

---

## üîô Building On

In **Lab 2**, you scaffolded a vertical slice. Now you'll add tests FIRST, before the implementation‚Äîtrue TDD with AI assistance.

**Key connection:** The scaffold from Lab 2 gives you something to test. Tests verify the AI-generated code actually works.

---

## Timebox

60‚Äì90 minutes

## Prerequisites

- Completed Labs 0‚Äì2
- Review [Prompt Pack V1](../../../shared/reference-materials/PROMPT_PACK_V1.md) ‚Äî focus on P2 (Tests-first)
- Review [Domain Context](../../../shared/reference-materials/DOMAIN_CONTEXT.md) for business context

## Domain Context

Use the **Order Management** domain from `docs/shared/reference-materials/DOMAIN_CONTEXT.md`. Your acceptance criteria should relate to Orders, Customers, or Items entities.

### Sample Acceptance Criteria (if lead doesn't provide)

- Given an order ID, return the order with customer name and item list
- Return 404 with Problem Details if order not found
- Order total should be calculated from item prices
- Orders can be filtered by status (pending, completed, cancelled)

## Inputs

Lead provides 3‚Äì6 acceptance criteria bullets (or use samples above).

## Steps

1. Use Prompt P2 (tests-first).
2. Review the generated tests for correctness and realism.
3. Fix the tests where needed (humans own quality).
4. Implement minimal code to pass.
5. Run full test suite.

## Success Criteria

- Tests match acceptance criteria
- Minimal code change to satisfy tests
- PR includes test commands executed

---

## Submission (MANDATORY)

### Step 1: Create Your Working Folder

```
/working/{frontend|backend}/{your_name}_{YYYYMMDD_HHMM}/
```

Example: `/working/backend/jsmith_20260121_1400/`

### Step 2: Include Required Files

- Test files (written BEFORE implementation)
- Implementation files (minimal to pass tests)
- A `README.md` containing:
  - Your name and date
  - Lab number: **Lab 3**
  - Acceptance criteria used
  - Tests generated by Copilot vs tests you fixed
  - Test commands run and results (pass/fail counts)

### Step 3: Open a Pull Request

- Use the PR template at `.github/pull_request_template.md`
- Ensure all checklist items are completed
- Highlight which tests Copilot got right vs wrong

### Example Folder Structure

```
/working/backend/jsmith_20260121_1400/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îî‚îÄ‚îÄ OrderService.java
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ OrderServiceTest.java
```

> üìÅ **Reference:** See `/working/frontend/example_lab3/` or `/working/backend/example_lab3/` for example submissions.

---

## Quick Reflection (2 min)

Before submitting, answer in your README:

- Did writing tests first change how you thought about the implementation?
- What did Copilot get wrong in the generated tests?
- How much time did you spend fixing tests vs writing code?

---

## üîú Looking Ahead

In **Lab 4**, the tests you just wrote become your safety net for refactoring. With comprehensive test coverage, you can confidently improve code structure without fear of breaking functionality.

**Next skill:** Prompt P4 (Guarded refactor) lets you improve code safely. Tests catch regressions automatically.

---

## Navigation

| Previous                                    | Home                        | Next                                 |
| ------------------------------------------- | --------------------------- | ------------------------------------ |
| [‚Üê Lab 2](LAB_2_SCAFFOLD_VERTICAL_SLICE.md) | [Week 1 Home](../README.md) | [Lab 4 ‚Üí](LAB_4_REFACTOR_GUARDED.md) |
